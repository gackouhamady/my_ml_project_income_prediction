# ðŸ’° Census Income Classification (U.S. CPS/ASEC 2019)

[![Python](https://img.shields.io/badge/Python-3.10+-blue?logo=python)](#-getting-started)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](#-license)
[![Dataset](https://img.shields.io/badge/Dataset-Census%20Income%20(ASEC)-lightgrey)](#-dataset)
[![Reproducible](https://img.shields.io/badge/Reproducible-Yes-success)](#-configuration)
[![CI Ready](https://img.shields.io/badge/CI-GitHub_Actions-blue?logo=github)](#-project-structure)

> Predict whether an individualâ€™s annual income exceeds **$50K** using the U.S. **Current Population Survey (CPS) / Annual Social and Economic (ASEC)** dataset â€” one of the most comprehensive labor, income, and demographic datasets in the U.S.

---

## ðŸ“¦ Project Overview

This project builds a **binary classification** model to predict income level (`â‰¤50K` or `>50K`) based on demographic and employment attributes from the **CPS ASEC microdata**.  
The workflow follows a **reproducible ML pipeline** with well-defined configuration and modular code organization.

---

## ðŸ§± Project Structure

```bash
census-income-classification/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                  # Raw CPS/ASEC or extracted UCI files
â”‚   â”œâ”€â”€ interim/              # Cleaned intermediate files
â”‚   â””â”€â”€ processed/            # Final ML-ready datasets
â”œâ”€â”€ models/                   # Saved models, checkpoints
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ figures/              # Visualizations (EDA, feature importance)
â”‚   â””â”€â”€ metrics/              # Performance logs / JSON reports
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ preprocess.py         # Feature cleaning, encoding, scaling
â”‚   â”œâ”€â”€ train.py              # Baseline & advanced model training
â”‚   â”œâ”€â”€ evaluate.py           # Metrics computation (AUC, F1, etc.)
â”‚   â””â”€â”€ infer.py              # Predict new samples
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ dataio/               # Data loading and utilities
â”‚   â”œâ”€â”€ features/             # Preprocessing pipeline
â”‚   â”œâ”€â”€ models/               # ML algorithms (sklearn, XGBoost)
â”‚   â”œâ”€â”€ metrics/              # Custom metrics for imbalanced data
â”‚   â””â”€â”€ utils/                # Logging, config parsing
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ __init__.py
â”œ
â”‚â”€â”€ 01_EDA.ipynb
â”‚â”€â”€ 02_Baseline_Experiment.ipynb
â”‚â”€â”€ 03_Final_Model_Experiment.ipynb
â”œâ”€â”€ config.yml                # YAML configuration (paths, hyperparams)
â”œâ”€â”€ requirements.txt          # Dependencies
â”œâ”€â”€ start.sh                  # Environment bootstrap script
â”œâ”€â”€ LICENSE                   # MIT license
â””â”€â”€ README.md
````

##  Dataset

- Source: U.S. Census Bureau â€” CPS ASEC
 

- census_income_additional_info

- Donors: Terran Lane & Ronny Kohavi, Silicon Graphics

- census_income_metadata

- Task: Predict income threshold at $50K

- Train instances: 199,523 (46,716 duplicates)

- Test instances: 99,762 (20,936 duplicates)

- Features: 40 (7 continuous, 33 nominal)

- Class imbalance:

- â‰¤ $50K â†’ 93.8%

- $50K â†’ 6.2%

- Weights: Each record has an instance weight representing population counts (used for analysis, not model fitting).

- âš ï¸ Use the instance_weight only for evaluation or weighted metrics, not for training ML models.

## Configuration

- Example (config.yml):
``` yaml
project: census-income-classification
seed: 42
data:
  raw_dir: data/raw
  processed_dir: data/processed
target: income
weights_column: instance_weight
preprocessing:
  missing_strategy: median
  encoder: onehot
  scale: true
modeling:
  baseline: logistic_regression
  advanced: xgboost
cv:
  n_splits: 5
  stratify: true
metrics: [accuracy, f1, auroc, auprc]

```
## Getting Startet
``` powershell
# 1ï¸âƒ£ Create virtual environment
python -m venv .venv && source .venv/bin/activate

# 2ï¸âƒ£ Install dependencies
pip install -r requirements.txt

# 3ï¸âƒ£ Prepare data
python scripts/preprocess.py --config config.yml

# 4ï¸âƒ£ Train baseline model
python scripts/train.py --config config.yml

# 5ï¸âƒ£ Evaluate results
python scripts/evaluate.py --config config.yml

```
| Feature Example              | Description                         |
| ---------------------------- | ----------------------------------- |
| `age`                        | Continuous â€” age in years           |
| `education`                  | Highest educational attainment      |
| `occupation code`            | Detailed occupation recode          |
| `capital gains/losses`       | Continuous values                   |
| `marital status`             | Married / Never-married / Separated |
| `weeks worked`               | Number of working weeks in the year |
| `sex`, `race`, `citizenship` | Demographic features                |
| `income` *(target)*          | `â‰¤50K` or `>50K`                    |

## Models

- Baselines: Logistic Regression, Random Forest, Naive Bayes

- Boosted Trees: XGBoost / LightGBM

- Handling Imbalance: Class weights, SMOTE, threshold tuning

- Metrics: AUROC, AUPRC, F1, Recall@Precisionâ‰¥90%

## Notebooks

- 01_EDA.ipynb â€” Feature distributions, correlation heatmaps

- 02_Baseline_Experiment.ipynb â€” Logistic regression / Random forest

- 03_Final_Model_Experiment.ipynb â€” Hyperparameter tuning, feature importance, explainability (SHAP)

## Reproducibility

- Seeds fixed in config.yml

- Deterministic CV splits

- Versioned environments (requirements.txt)

- Modular scripts for pipeline reproducibility

## License

- This project is licensed under the MIT License â€” see the LICENSE file for details.

## References

- U.S. Census Bureau, Current Population Survey: 2019 ASEC Technical Documentation

- census_income_additional_info

- Census Income Metadata (Terran Lane & Ronny Kohavi, SGI)

- census_income_metadata
